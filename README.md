## Project Overview
This project involves analyzing employee data from the 1980s and 1990s at Pewlett Hackard. The task includes designing tables to hold the data from CSV files, importing the CSV files into a SQL database, and performing data analysis to answer specific questions about the data.

## Background
As a new data engineer at Pewlett Hackard, the task is to research people who were employed by the company during the 1980s and 1990s. The remaining data from that period is stored in six CSV files, which will be imported into a SQL database for analysis. The project involves data modeling, data engineering, and data analysis.

## Tools and Libraries Used
SQLAlchemy

PostgreSQL

Python

Jupyter Notebook

## Process Description
Data Modeling: Inspect the CSV files and sketch an Entity Relationship Diagram (ERD) of the tables using tools like QuickDBD. This step helps to visualize the relationships between different entities in the database.

Data Engineering: Create a table schema for each of the six CSV files, specifying data types, primary keys, foreign keys, and other constraints. Import each CSV file into its corresponding SQL table.

Data Analysis: Perform various queries on the database to extract insights from the data. This includes listing employee information, such as names, salaries, hire dates, and department details.

## Conclusion
This project demonstrates the process of designing a database schema, importing data from CSV files into a SQL database, and performing data analysis using SQL queries. The insights obtained from the analysis provide valuable information about Pewlett Hackard's employee data during the specified time period.
